[TOC]: # "大数据框架介绍与对比"

# 大数据框架介绍与对比
- [五种常用的大数据处理框架技术](#五种常用的大数据处理框架技术)
- [大数据处理框架是什么？](#大数据处理框架是什么)
- [批处理系统](#批处理系统)
  - [Apache Hadoop](#apache-hadoop)
    - [批处理模式](#批处理模式)
    - [优势和局限](#优势和局限)
    - [总结](#总结)
- [流处理系统](#流处理系统)
  - [Apache Storm](#apache-storm)
    - [流处理模式](#流处理模式)
    - [优势与局限](#优势与局限)
    - [总结](#总结-1)
  - [Apache Samza](#apache-samza)
    - [流处理模式](#流处理模式-1)
    - [优势和局限](#优势和局限-1)



## 五种常用的大数据处理框架技术

大数据（big data），IT行业术语，是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。

虽然处理数据所需的计算能力或存储容量早已超过一台计算机的上限，但这种计算类型的普遍性、规模以及价值在最近几年蔡经理了大规模扩展

本文将介绍大数据系统一个最基本的组件：处理框架。处理框架负责对系统中的数据进行计算，例如处理从非易失存储中读取的数据，或处理刚刚摄入到系统中的数据。数据的计算则是指从大量单一数据点中提取信息和见解的过程

本文将介绍这些框架

- 仅批处理框架：Apache Hadoop
- 仅流处理框架：Apache Storm、Apache Samza
- 混合框架：Apache Spark、Apache Flink

## 大数据处理框架是什么？

**处理框架**和**处理引擎**负责对数据系统中的数据进行计算。虽然“引擎“和”框架“之间的区别没有什么权威的定义，但大部分时候可以将前者定义为实际负责处理数据操作的组件，后者则可定义为承担类似作用的一系列组件。

例如**Apache Hadoop**可以看做一种以**MapReduce**作为默认处理引擎的处理框架。引擎和框架通常可以相互替换或同时使用。例如另一种框架**Apache Spark**可以纳入Hadoop并取代MapReduce。组件之间的这种互操作性是大数据系统灵活性如此之高的原因之一。

虽然负责处理声明周期内这一阶段数据的系统通常都很复杂，但从广义层面来看它们的目标是非常一致的：通过对数据执行操作提高理解能力，揭示出数据蕴含的模式，并针对复杂互动获得见解。

为了简化这些组件的讨论，我们会通过不同处理框架的设计意图，按照所处理的数据状态对其进行分类。一类系统可以用批处理方式处理数据，一些系统可以通过流方式处理连续不断流入系统的数据。此外还有一些系统可以同时处理这两类数据。

在深入介绍不同实现的指标和结论之前，首先需要对不同处理类型的概念进行一个简单的介绍。

## 批处理系统

**批处理**在大数据世界中有着悠久的历史。批处理主要操作大容量静态数据集，并在计算过程完成后返回结果。

批处理模式中使用的数据集通常复合下列特征：

- 有界：数据集代表数据的有限集合
- 持久：数据通常始终存储在某种类型的持久存储位置中
- 大量：批处理操作通常是处理极为海量数据集的唯一方法

批处理非常适合需要访问全套记录才能完成的计算工作。例如在计算总数和平均数的时候，必须将数据集作为一个整体加以处理，而不能将其视为多条记录的集合。这些操作要求在计算进行过程种数据维持自己的状态。

需要处理大量数据的任务通常最适合批处理操作进行处理。无论直接从持久存储设备处理数据集，或首先将数据集载入内存，批处理系统在设计过程中就充分考虑了数据的量，可提供充足的处理资源。由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析。

大量数据的处理需要付出大量的时间，因此批处理不适合对处理时间要求较高的场合

### Apache Hadoop

Apache Hadoop是一种专用于批处理的处理框架。Hadoop是首个在开源社区获得极大关注的大数据框架。基于谷歌有关海量数据处理所发表的多篇论文与经验的Hadoop重新实现了相关算法和组件对战，让大规模批处理技术变得更易用。

新版Hadoop包含多个组件，即多个层，通过配合使用可处理批数据：

- HDFS：HDFS是一种分布式文件系统层，可对集群节点间的存储和复制进行协调。HDFS确保了无法避免的节点故障后数据依然可用，可将其用作数据来源，可用于存储中间态的处理结果，并可存储计算的最终结果。
- YARN：YARN是Yet Another Resource Negotiator（另一个资源管理器）的缩写，可充当Hadoop堆栈的集群协调组件。该组件负责协调并管理底层资源和调度作业的运行。通过充当集群资源的接口，YARN使得用户能在Hadoop集群中使用比以往的迭代方式运行跟更多类型的工作负载
- MapReduce：MapReduce是Hadoop的原生批处理引擎。

#### 批处理模式

Hadoop的处理功能来自MapReduce引擎。MapReduce的处理技术符合使用键值对的map、shuffle、reduce算法要求。基本处理过程包括：

1. 从HDFS文件系统读取数据集
2. 将数据集拆分成小块并分配给所有可用节点
3. 针对每个节点上的数据子集进行计算（计算的中间态结果会重新写入HDFS）
4. 重新分类中间态结果并按照键进行分组
5. 通过对每个节点计算的结果进行汇总和组合对每个键的值进行“Reducing”
6. 将计算而来的最终结果重新写入HDFS

#### 优势和局限

由于这种方法严重依赖持久存储，每个任务需要多次执行读取和写入操作，因此速度相对较慢。但另一方面由于磁盘空间通常是服务器上最丰富的资源，这意味着MapReduce可以处理非常海量的数据集。同时也意味着相比其他类似技术，Hadoop的MapReduce通常可以在廉价硬件上运行，因为该技术并不需要将一切都存储在内存中。MapReduce具备极高的缩放潜力，生产环境中曾经出现过包含数万个节点的引用。

MapReduce的学习曲线较为陡峭，虽然Hadoop生态系统的其他周边技术可以大幅降低这一问题的影响，但通过Hadoop集群快速实现某些应用时依然需要注意这个问题。

围绕Hadoop已经形成了辽阔的生态系统，Hadoop集群本身也经常被用作其他软件的组成部件。很多其他处理框架和引擎通过与Hadoop集成可以是用HDFS和YARN资源管理器

#### 总结

Apache Hadoop及其MapReduce处理引用提供了一套久经考验的批处理模型，最适合处理对时间要求不高的非常大规模数据集，通过非常低成本的组件即可搭建完整功能的Hadoop集群，使得这一廉价且高效的处理技术可以灵活应用在很多案例中。与其他框架和引擎的兼容和继承能力使得Hadoop可以成为使用不同技术的多种工作负载处理平台的底层基础。

## 流处理系统

流处理系统会对随时进入系统的数据进行计算。相比批处理模式，这是一种截然不同的处理方式。流处理方式无需对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作

流处理中的数据集是“无边界”的，这就产生了几个重要的影响：

- 完整数据集只能代表截止目前已经进入到系统中的数据总量
- 工作数据集也许更相关，在特定时间只能代表某个单一数据项。
- 处理工作时基于事件的，除非明确停止否则没有”尽头“。处理结果立即可用，并会随着新数据的抵达继续更新。

流处理系统可以处理几乎无限量的数据，但同一时间只能处理一条（真正的流处理）或很少量（微批处理，Micro-batch Processing）数据，不同记录间只维持最少量的状态。虽然大部分系统提供了用于维持某些状态的方法，但流处理主要针对副作用更少，更加功能性的处理（Functional processing）进行优化。

功能性操作主要侧重于状态或副作用有限的离散步骤。针对同一个数据执行同一个操作忽略其他因素产生相同的结果，此类处理非常适合流处理，因为不同项的状态通常是某些困难、限制，以及某些情况下不需要结果的结合体。因此某些类型的状态给管理通常是可行的，但这些框架通常在不具备状态管理机制时更简单也更高效。

此类处理非常适合某些类型的工作负载。有近实时处理需求的任务很适合使用流处理模式。分析、服务器或应用程序错误日志，以及其他基于时间的衡量指标是最适合的类型，因为对这些领域的数据变化做出响应对于业务职能来说是极为关键的。流处理很适合用来处理必须对变动或峰值做出相应，并且关注一段时间内变化趋势的数据。

### Apache Storm

Apache Storm是一种侧重于极低延迟的流处理框架，也许是要求近实时处理的工作负载的最佳选择。该技术可以处理非常大量的数据，通过比其他解决方案更低的延迟提供结果。

#### 流处理模式

Storm的流处理可对框架中名为Topology（拓扑）的DAG（Directed Acyclic Graph，有向无环图）进行编排。这些拓扑描述了当数据片段进入系统后，需要对每个传入的片段执行的不同转换或步骤。

拓扑包含：

- Stream：普通数据流，这是一种会持续抵达系统的无边界数据。
- Spout：位于拓扑边缘的数据流来源，例如可以是API或查询等，从这里可以产生待处理的数据。
- Bolt：Bolt代表需要消耗流数据，对其应用操作，并将结果以流的形式进行输出的处理步骤。Bolt需要与每个Spout建立连接，随后相互连接以组成所有必要的处理。在拓扑的尾部，可以使用最终的Bolt输出作为相互连接的其他系统的输入。

Storm背后的想法是使用上述组件定义大量小型的离散操作，随后将多个组件组成拓扑。默认情况下Storm提供了“至少一次”的处理保证，这意味着可以确保每条消息至少可以被处理一次，但某些情况下如果遇到失败可能会处理多次。Storm无法确保可以按照特定顺序处理消息。

为了实现严格的一次处理，即有状态处理，可以使用一种名为Trident的抽象。严格来说不使用Trident的Storm通常可以称之为Core Storm。Trident会对Storm的处理能力产生极大影响，会增加延迟，为处理提供状态，使用微批处理代替逐项处理的纯粹流处理模式。

为避免这些问题，通常建议Storm用户尽可能使用Core Storm。然而也要注意，Trident对内容严格的一次处理保证在某些情况下也比较有用，例如想要计算一个小时内有多少用户点击了某个链接，此时Trident将是你唯一的选择。尽管不能充分发挥框架与生俱来的优势，但Trident提高了Storm的灵活性。

Trident拓扑包括：

- 流批（Stream batch）：这是指流数据的微批，可通过分库那提供批处理语义。
- 操作（Operation）：是指可以对数据执行的批处理过程

#### 优势与局限

目前来说Storm可能是近实时处理领域的最佳解决方案。该技术可以用极低的延迟处理数据，可用于希望获得最低延迟的工作负载。如果处理速度直接影响用户体验，例如需要将处理结果直接提供给访客打开的网站页面，此时Storm将会是一个很好的选择。

Storm与Trident配合使得用户可以用微批代替纯粹的流处理。虽然借此用户可以获得更大灵活性打造更符合要求的工具，但同时这种做法会削弱该技术相比其他解决方案最大的优势。话虽如此，但多一种流处理方式总是好的。

Core Storm无法保证消息的处理顺序。Core Storm为消息提供了“至少一次”的处理保证，这意味着可以保证每条数据都能被处理，但也可能发生重复。Trident提供了严格的一次处理保证，可以在不同批之间提供顺序处理，但无法在一个批内部实现顺序处理。

在互操作性方面，Storm可与Hadoop的YARN资源管理器进行集成，因此可以很方便地融入现有Hadoop部署。除了支持大部分处理框架，Storm还可支持多种语言，为用户的拓扑定义提供了更多选择。

#### 总结

对于延迟需求很高的纯粹的流处理工作负载，Storm可能是最适合的技术。该技术可以保证每条消息都被处理，可配合多种编程语言使用。由于Storm无法进行批处理，如果需要这些能力可能还需要使用其他组件。如果对严格的一次处理保证有比较高的要求，此时可考虑使用Trident。不过这种情况下其他流处理框架也许更适合。

### Apache Samza

Apache Samza是一种与Apache Kafka消息系统紧密绑定的流处理框架。虽然Kafka可用于很多流处理系统。但按照设计，Samza可以更好地发挥Kafka独特的架构优势和保障。该技术可通过Kafka提供容错、缓冲，以及状态存储。

Samza可使用YARN作为资源管理器。这意味着默认情况下需要具备Hadoop集群（至少具备HDFS和YARN），但同时也意味着Samza可以直接使用YARN丰富的内建功能。

#### 流处理模式

Samza依赖Kafka的语义定义流的处理方式。Kafka在处理数据时设计下列概念：

- Topic（话题）：进入Kafka系统的每个数据流可称之为一个话题。话题基本是一种可供消费者订阅的，由相关信息组成的数据流。
- partition（分区）：为了将一个话题分散至多个节点，Kafka会将传入的消息划分至同一个分区。分区的顺序可获得保证。
- Broker（代理）：组成Kafka集群的每个节点也叫作代理
- Producer（生成方）：任何从Kafka读取话题的组件可叫做消耗方。消耗方需要负责维持有关自己的分支信息，这样即可在失败后知道那些记录已经被处理过了。

由于Kafka相当于永恒不变的日志，Samza也需要处理永恒不变的数据流。这意味着任何转换创建的新数据流都可被其他组件所使用，而不会对最初的数据流产生影响。

#### 优势和局限

乍看之下，Samza对Kafka类查询系统的依赖似乎是一种限制，然而这也可以为系统提供一些独特的保证和功能，这些内容也是其他流处理系统不具备的

例如Kafka已经提供了可以通过低延迟方式访问的数据存储副本，此外还可以为每个数据分区提供非常易用且低成本的多订阅者模型。所有输出内容，包括中间态的结果都可以写入到Kafka，并可被下游步骤独立使用。

这种对Kafka的紧密依赖在很多方面类似于MapReduce引擎对HDFS的依赖。虽然在批处理的每个计算之间对HDFS的依赖导致了一些严重的性能问题，但也避免了对流处理遇到的很多其他问题。

Samza与Kafka之间的紧密的关系使得步骤本身可以非常松散的耦合在一起。无需事先协调，即可在输出的任何步骤中增加任意数量的订阅者，对于有多个团队需要访问类似数据的组织，这个特性非常有用。多个团队可以全部订阅进入系统的数据话题，或任意订阅其他团队对数据进行够某些处理后创建的话题。这一切并不会对数据库等负载紧密型基础架构造成额外的压力。

直接写入Kafka还可以避免回压（Backpressure）问题。回压是指当负载峰值导致数据流入速度超过组件实时处理能力的情况，这种情况可能导致工作停顿并可能丢失数据。按照设计，Kafka可以将数据保存很长时间，这意味着组件可以在方便的时候继续进行处理，并可直接重启动无需担心造成任何后果

Samza可以使用以本地键值存储方式实现的容错检查点系统存储数据。这样Samza即可获得“至少一次“的交付保障，但面对由于数据可能多次交付造成的失败，该技术无法对汇总后的状态（例如计数）提供精确恢复。

Samza提供的高级抽象使其在很多方面比Storm等系统提供的基元（Primitive）更易于配合使用。目前Samza只支持JVM语言，这意味着它在语言支持方面不如Storm灵活。

#### 总结

对于已经具备或易于实现Hadoop和Kafka的环境，Apache Samza是流处理工作负载一个很好的选择。Samza本身很适合有多个团队需要使用（但相互之间并不一定紧密协调）不同处理阶段的多个数据流的组织。Samza可大幅简化很多流处理工作，可实现低延迟的性能。如果部署要求与当前系统不兼容，也许并不适合使用，但如果需要极低延迟的处理，或对严格的一次处理语义有较高需求，此时依然适合考虑。

## 混合处理系统：批处理和流处理

一些处理框架可同时处理批处理和流处理工作负载。这些框架可以用相同或相关的组件和API处理两种类型的数据，借此让不同的处理需求得以简化。

如你所见，这一特性主要是由Spark和Flink实现的，下文将介绍这两种框架。实现这样的功能重点在于两种不同处理模式如何进行统一，以及要对固定和不固定的数据集之间的关系进行何种假设。

虽然侧重于某一种类型的项目会更好的满足具体用例的要求，但混合框架意在提供一种数据处理的通用解决方案。这种框架不仅可以提供数据所需的处理方法，而且提供了自己的集成项、库、工具、可胜任图形分析、机器学习、交互式查询等多种任务。

### Apache Spark

Apache Spark是一种包含流处理能力的批处理框架。与Hadoop的MapReduce引擎基于各种相同原则开发而来的Spark主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度。

Spark可作为独立集群部署（需要相应存储层的配合），或可与Hadoop集成并取代MapReduce引擎。

#### 批处理模式

与MapReduce不同，Spark的数据处理工作全部在内存中进行，只在一开始将数据读入内存，以及将最终结果持久存储是需要与存储层交互。所有的中间态的处理结果均存储在内存中。

虽然内存中处理方式可大幅改善性能，Spark在处理与硬盘有关的任务时速度也有很大提升，因为通过提前对整个任务集进行分析可以实现更完善的整体式优化。为此Spark可创建代表所需执行的全部操作，需要操作的数据，以及操作和数据之间关系的DAG，借此处理器可以对任务进行更智能的协调。

为了实现内存中批计算，Spark会使用一种名为Resilient Distributed Dataset（弹性分布式数据集），即RDD的模型来处理数据，这是一种代表数据集，只位于内存中，永恒不变的结构。针对RDD执行的操作可生成新的RDD。每个RDD可以通过世系（Lineage）回溯到父级RDD，并最终回溯至磁盘上的数据。Spark可通过RDD在无需将每个操作的结果写回到磁盘的前提下实现容错。

#### 流处理模式

流处理能力是由Spark Streaming实现的。Spark本身在设计上主要面向批处理工作负载，为了弥补引擎设计和流处理工作负载特征
